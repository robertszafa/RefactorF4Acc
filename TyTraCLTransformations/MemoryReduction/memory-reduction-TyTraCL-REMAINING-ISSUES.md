# REMAINING ISSUES : Memory (Bandwidth) Reduction for Scientific Computing on GPUs


## 2021-06-14

Lots of issues have cropped up with Autoparallel-Fortran, all related to wrong handling of parameters in stencils. 
I guess I should run a constant folding step first before running that compiler.

The inliner is still buggy too: 

      * parameters are renamed when they shouldn't. => OK, they should anyway.
      * parameters are turned into arguments when they shouldn't. => Maybe OK
      * parameters are removed when they shouldn't. => OK, this was the subroutine extractor, not the inliner.

Parameters in stencils lead to a bug because
	
      [sort keys %{ $state->{'StreamVars'}{$var}{'Set'} }]

has names with the parameters in them but

      $ordered_stencil_var_tuple

has names with the parameters folded into constants

So what we could do is fold the constants in the AST using fold_constants_in_expr() before we run _scalarise_array_accesses_in_ast()

## 2021-06-11

* Easy solution for Purpose: put it in purpose.cfg, simply

            var1 = In
            var2 = Temp

      We can even have namespaces:

            les::p = Out
      
      etc

* We can trivially generate this from the pragmas
* We read this in at some point in the memory_reduction.pl script
* All we need to do is check where in MemoryReduction.pm or TyTraCL.pm this is used

MemoryReduction on 2-D Shallow Water

The original code has two subroutines

map/fold analysis results in 5 subroutines + superkernel
memory reduction results in 40 subroutines: superkernel, scalar versions of the 5 maps, a stage kernel, 5 wrappers, 18 intermediate ones
inlining results in a single superkernel





## 2021-06-11

I ran the inliner on the code generated by the MemoryReduction algorithm, and there are three issues:
1. The names are way too long. => I solved this by shortening the names with `md5()`
2. Some variables are not declared. => Solved, this was an issue with DeclCount which counts across passes. I changed it to a hash
3. There are lots of argument declarations that have no corresponding argument => Fixed, reason was missing ArgDecl in $info
4. slices are now a(1,:)(1) and should be a(1,1) => OK, solved with a regex
5. stencil constants are losing their DIMENSION attribute => OK, I had never implemented this
6. parameter declarations are replicated, need to see how I can avoid that. => OK, done

## 2021-06-10

Full 2-D shallow water, needs some changes:

1/ remove dimension(1) as this is now obsolete
2/ remove local arrays from args, manually. Later we'll use the "Purpose" pragma for this.
Ideally I would have 4 values for Purpose: In, Out, Temp and Local:
- In and Out are proper args of the superkernel
- Temp are arrays at topleve in the superkernel
- Local are arrays that are only used inside a subkernel

I still struggle with arrays that are actually InOut, such as `wet`. As it is modified, it needs to be returned. And as I don't have InOut, I make it Out
In are arrays not returned. So any array returned becomes Out? Need to test what happens if I make them InOut.
I tried this and it makes no difference: Out or InOut have the same result. So I can keep InOut.

It looks like I had better run an aggressive argument detection analysis first, before I generate the Haskell AST. At the very least that would remove lots of args that ought to be local scalar vars, like `duu`.
=> OK, I did that.
Also fixed a small bug in the removeIntent function in AutoParallel-Fortran, it did not take leading spaces into account.

If I want some reduction in memory I need to exclude the updates to h and wet:

   h(j,k) = hzero(j,k) + eta(j,k)
   wet(j,k) = 1
   if (h(j,k)<hmin) wet(j,k) = 0

These will be done on the host so that we don't have to use memory for hzero or for the output of wet on the device

By doing so, the kernel uses the following 8 arrays:

    real, dimension(1:252004) :: eta_0
    integer, dimension(1:252004) :: wet_0
    real, dimension(1:252004) :: u_0
    real, dimension(1:252004) :: v_0
    real, dimension(1:252004) :: h_0
    real, dimension(1:252004) :: un_1
    real, dimension(1:252004) :: vn_1
    real, dimension(1:252004) :: eta_1

The original CPU code has 9 global arrays

      REAL :: hzero(0:ny+1,0:nx+1)
      REAL :: h(0:ny+1,0:nx+1)
      REAL :: eta(0:ny+1,0:nx+1)
      REAL :: etan(0:ny+1,0:nx+1)
      REAL :: u(0:ny+1,0:nx+1)
      REAL :: un(0:ny+1,0:nx+1)
      REAL :: v(0:ny+1,0:nx+1)
      REAL :: vn(0:ny+1,0:nx+1)
      INTEGER :: wet(0:ny+1,0:nx+1)

and two local arrays in `dyn`

      REAL :: du(0:ny+1,0:nx+1)
      REAL :: dv(0:ny+1,0:nx+1) 

and the generated GPU code has the same 11 arrays, all `__global`

      real, dimension(0:(ny + 1),0:(nx + 1)) :: eta
      real, dimension(0:(ny + 1),0:(nx + 1)) :: u
      real, dimension(0:(ny_dyn + 1),0:(nx_dyn + 1)) :: du_dyn
      integer, dimension(0:(ny + 1),0:(nx + 1)) :: wet
      real, dimension(0:(ny + 1),0:(nx + 1)) :: v
      real, dimension(0:(ny_dyn + 1),0:(nx_dyn + 1)) :: dv_dyn
      real, dimension(0:(ny + 1),0:(nx + 1)) :: un
      real, dimension(0:(ny + 1),0:(nx + 1)) :: h
      real, dimension(0:(ny + 1),0:(nx + 1)) :: vn
      real, dimension(0:(ny + 1),0:(nx + 1)) :: etan
      real, dimension(0:(ny + 1),0:(nx + 1)) :: hzero
  
So from a device perspective we save 3 arrays out of 11, or 27% of the array memory on the device.

The "Purpose" pragma is really essential as currently I make following manual change:

ORIGINAL

  real, dimension(0:(ny + 1),0:(nx + 1)), intent(InOut) :: eta                Purpose(Out)
  real, dimension(0:(ny + 1),0:(nx + 1)), intent(InOut) :: u                  Purpose(In)
  real, dimension(0:(ny_dyn + 1),0:(nx_dyn + 1)), intent(InOut) :: du_dyn     Purpose(Local)
  integer, dimension(0:(ny + 1),0:(nx + 1)), intent(InOut) :: wet             Purpose(In)
  real, dimension(0:(ny + 1),0:(nx + 1)), intent(InOut) :: v                  Purpose(In)
  real, dimension(0:(ny_dyn + 1),0:(nx_dyn + 1)), intent(InOut) :: dv_dyn     Purpose(Local)
  real, dimension(0:(ny + 1),0:(nx + 1)), intent(InOut) :: un                 Purpose(Out)
  real, dimension(0:(ny + 1),0:(nx + 1)), intent(InOut) :: h                  Purpose(In)
  real, dimension(0:(ny + 1),0:(nx + 1)), intent(InOut) :: vn                 Purpose(Out)
  real, dimension(0:(ny + 1),0:(nx + 1)), intent(InOut) :: etan               Purpose(Temp)
  real, dimension(0:(ny + 1),0:(nx + 1)), intent(In) :: hzero                 Purpose(In)

MANUAL CHANGES

  real, dimension(0:(ny + 1),0:(nx + 1)), intent(InOut) :: eta
  real, dimension(0:(ny + 1),0:(nx + 1)), intent(In) :: u
  real, dimension(0:(ny + 1),0:(nx + 1)) :: du_dyn
  integer, dimension(0:(ny + 1),0:(nx + 1)), intent(In) :: wet
  real, dimension(0:(ny + 1),0:(nx + 1)), intent(In) :: v
  real, dimension(0:(ny + 1),0:(nx + 1)) :: dv_dyn
  real, dimension(0:(ny + 1),0:(nx + 1)), intent(Out) :: un
  real, dimension(0:(ny + 1),0:(nx + 1)), intent(In) :: h
  real, dimension(0:(ny + 1),0:(nx + 1)), intent(Out) :: vn
  real, dimension(0:(ny + 1),0:(nx + 1)) :: etan
  real, dimension(0:(ny + 1),0:(nx + 1)), intent(In) :: hzero

I now have the parser for the Purpose pragma in place. I think I will store it in 

	$stref->{'Subroutines'}{ $stref->{'Top'} }{'Purpose'} =
	{ 
            $info->{'VarDecl'}{'Name} => $info->{'Pragmas'}{'Purpose'},
            ...
      }

I think what we might want to do is emit a file with that information, simply with Data::Dumper I suppose.
Then we can always read it back in. We could in fact generalise this for other pragmas, but of course only if the does not depend on the location in the source file. So this is OK for pragmas that apply to declarations only, i.e. Halo, MemSpace, Purpose. 


## 2021-06-09

Regression testing using LES. Main reason for breakages was the 'Hook' approach, removed it. Also the fix_end_lines, had to revert it to the release version.

## 2021-06-08

Fixing the inliner and the Fortran-to-C/OpenCL translator

Fortran 77 -Perl-> pure Fortran 95 -Haskell-> OpenCL Fortran 95 -Perl-> TyTraCL with Fortran 95 kernels -Haskell-> OpenCL Fortran 95 -Perl-> OpenCL C

## 2021-05-07

- The pointer analysis needed more sophistication. Should be OK now. Also subs in used modules are now emitted as C code. 
- I can now also generate OpenCL C from the generated kernel code. The main program is not OpenCL, but it is probably not a big task to do that.

- I want to have a single kernel driver subroutine in an iterative loop. What this means is that I should use the 

      !$RF4A Subroutine $sub_name
      ...
      !$ACC End Subroutine $sub_name

but any subroutine called in this region should be inlined.

In other words, the !$RF4A Subroutine region should work exactly as the 

    !$RF4A Begin Inline
    ...
    !$RF4A End Inline 

region

* We have `{Begin|End}KernelWrapper` which seems to be a synonym for `Subroutine`, so that is OK.
* We also have `HasKernelRegion` and `{Begin|End}Kernel`: 

            if (exists $info->{'Pragmas'}{'BeginKernel'}) {
                  $Sf->{'HasKernelRegion'}=1;
            }

      This is used as follows:
      - If in `analyse_lines()` we encounter

            !$RF4A Begin Kernel 

      we set `HasKernelRegion` on that subroutine. 
      - Then in `mark_blocks_between_calls`, we look for a  `{Begin|End}Kernel` block. If this is not enclosing a subroutine call, we mark it with 

            !$RF4A Subroutine 
      
      - All these subroutines are added to `$stref->{'KernelSubs'}` but that is unused. All marked blocks it will be extracted in the next pass, `refactor_marked_blocks_into_subroutines()`. 

      - So this is simply a way to mark anything not a subroutine call so that it will become a subroutine call.

* We also have `{Begin|End}KernelSub`. Each subroutine call intended for offloading in the `KernelWrapper` region should be enclosed in a `KernelSub` region. Then it is added to `$stref->{'KernelWrappers'}{$kernel_wrapper_name}{'KernelSubs'}`, otherwise it goes into `OtherCalls`. This was intended for Analysis::LoopDetect and Analysis::KernelArgs, but these were never finished. So I can ignore this for the moment.

What I want is that there is a single subroutine which will be offloaded. So if I mark a region with `Inline` that should do what I want. So what we do is:

      !$ACC Subroutine dyn_shapiro_update
      !$ACC Begin Inline 
      ...
      !$ACC End Inline
      !$ACC End Subroutine dyn_shapiro_update

and that seems to work but needs to be tested.


## 2021-06-03

### TODO
- Do the full 2-D Shallow Water
- Create a SOR based on LES, with 1/2/3/4 unrolls
- Get both to work on GPU => Fix/Check OpenCL code generation. Currently there are a few issues.
The key one is that the conversion from Fortran types to pointers is quite wrong. And this is because the "return into array" is wrong:

program main
integer, dimension(1:252004) :: wet_1
do global_id=1,252004
  call stage_kernel_1(wet_1)
end do
end program main  

subroutine stage_kernel_1(wet_1)
    integer, dimension(1:252004), intent(Out) :: wet_1
    integer :: idx
    call get_global_id(idx,0)
    call update_map_24( wet_1(idx))
end subroutine stage_kernel_1

subroutine update_map_24( wet_1)
    integer, intent(Out) :: wet_1
    call update_map_24_scal( wet_1)
end subroutine update_map_24

subroutine update_map_24_scal(wet_j_k)
    integer, intent(Out) :: wet_j_k
  wet_j_k = 1
end subroutine update_map_24_scal

Should be

void  main () {
      int* wet_1;
      for (...) {
            stage_kernel_1(wet_1)
      }
}
void stage_kernel_1(int * wet_1) { // Out
    int idx = get_global_id(0);
    update_map_24( &wet_1[idx]); 
}

void update_map_24(int* wet_1) { // Out
    update_map_24_scal( wet_1);
}

void update_map_24_scal(int* wet_j_k) { // Out
  *wet_j_k = 1;
}

But it currently is

void main() {
    int *wet_1;
    // Loops over stage calls
    for (int global_id = 1;global_id <= 252004;global_id += 1) {
        // WRONG!   
        stage_kernel_1(*wet_1);
    }
}

void stage_kernel_1(int *wet_1) {
    int idx; 
    global_id = get_global_id(0); // WRONG! should be idx => FIXED
    // WRONG, should have &
    update_map_24(wet_1[F1D2C(1 , idx)]);
}

void update_map_24(int *wet_1) {

    update_map_24_scal(*wet_1);
}

void update_map_24_scal(int *wet_j_k) {
      // WRONG, should be *
    wet_j_k = 1;
}
 
Scalar Pointers should be derefed unless they are pointer args or in the case of a ptr = ptr assignment
(although even then one might wonder if *ptr1 = *ptr2 is not safer)
=> Solution: make all args pointers and deal with expressions as call args

### Major issue: output tuple code generation is entirely wrong!

=> I think this is now fixed!

* The "quick fix" for VT is not good and in fact the whole getInputArgs is not good because it can't distinguish between real scalars and scalars in vectors.
A possible solution is to do an everywhere that changes any Vec VT (Scalar VT  ...) into Vec VT (Scalar VDC  ...), then it is likely OK
* But the biggest problem is that the TyTraCL code is

      vec_h_1_0 = unzipt (map update_map_24 zipt (hzero_0, un_0))
      vec_h_1_1 = elt 0 vec_h_1_0
      h_1 = vec_h_1_1
      vec_u_1_0 = unzipt (map update_map_24 zipt (hzero_0, un_0))
      vec_u_1_1 = elt 1 vec_u_1_0
      u_1 = vec_u_1_1

which is already sub-optimal as is should simply be

      vec_h_1_0_u_1_0 = unzipt (map update_map_24 zipt (hzero_0, un_0))
      vec_h_1_1 = elt 0 vec_h_1_0_u_1_0
      h_1 = vec_h_1_1
      vec_u_1_1 = elt 1 vec_h_1_0_u_1_0
      u_1 = vec_u_1_1

But what is generated is

      ! Map
      call update_map_24(hzero_0(idx), un_0(idx), vec_h_1_0)
      vec_h_1_1 = vec_h_1_0
      h_1(idx) = vec_h_1_1
      ! Map
      call update_map_24(hzero_0(idx), un_0(idx), vec_u_1_0)
      vec_u_1_1 = vec_u_1_0
      u_1(idx) = vec_u_1_1

What this should be is       
      ! Map
      call update_map_24(hzero_0(idx), un_0(idx), vec_h_1_0, vec_u_1_0)
      vec_h_1_1 = vec_h_1_0
      h_1(idx) = vec_h_1_1
      vec_u_1_1 = vec_u_1_0
      u_1(idx) = vec_u_1_1

The likely reason is that the LHS is (Vec VT ...) but the RHS is Unzipt, this is wrong: Either the RHS should have Elt applied or the LHS should be a Tuple 


-- Fuse stencils
(Vec VO (Scalar VDC DFloat "h_1"),Elt 0 (UnzipT (Map (Function "update_map_24" []) (ZipT [Vec VI (Scalar VDC DFloat "hzero_0"),Vec VI (Scalar VDC DFloat "un_0")]))))
(Vec VO (Scalar VDC DFloat "u_1"),Elt 1 (UnzipT (Map (Function "update_map_24" []) (ZipT [Vec VI (Scalar VDC DFloat "hzero_0"),Vec VI (Scalar VDC DFloat "un_0")]))))

We want to check the AST for tuples that have Elt n expr and maybe we simply build a map

      expr => [(lhs1,n1),(lhs2,n2)]

Then we built new AST tuples that look like (Tuple [lhs1,lhs2],expr)

foldl (\acc (lhs,rhs) -> case rhs of
      Elt n expr -> if Map.member expr acc 
            then 
                  let
                        lst = acc ! expr
                  in
                        Map.update expr (lst++[(lhs,n)]) acc
            else 
            Map.insert expr [(lhs,n)] acc
      _ -> acc


) Map.empty ast



-- Decompose expressions 
(Vec VT (Scalar VT DFloat "vec_h_1_0"),UnzipT (Map (Function "update_map_24" []) (ZipT [Vec VI (Scalar VDC DFloat "hzero_0"),Vec VI (Scalar VDC DFloat "un_0")])))
(Vec VT (Scalar VT DFloat "vec_h_1_1"),Elt 0 (Vec VT (Scalar VT DFloat "vec_h_1_0")))
(Vec VO (Scalar VDC DFloat "h_1"),Vec VT (Scalar VT DFloat "vec_h_1_1"))

Getting closer, we have the tuples restored but the decomposition is wrong (should not happen)

### Local Arrays, iteration ranges

- The code I added to reduce the bounds in the calls to the stages should be removed

- Local arrays should be marked as such in the superkernel code. My idea would be to let the scientist mark the In and Out arrays as such:

      real, dimension(...) :: v !$RF4A Purpose(In|Out)

and make sure this gets passed on to the generated code      

- The NDRange from the host code should also be present in the kernel code as an annotation:

      !$RF4A NDRange($nd_range)

This will be in particular important for GPU-style folds, see next.      

### GPU fold

We need to generate code for a GPU-style fold. Contrary to what the AutoParallelFortran compiler does, I think it is OK to assume that get_global_id() starts from 1 for Fortran 


subroutine reduce(ARRAY,global_ACC_array)


    integer :: chunk_size
    integer :: local_id
    integer :: group_id
    integer :: r_iter
    integer :: idx
    integer :: ndrange
    integer :: ndrange_padded
    integer :: nthreads
    integer :: local_chunk_size
    integer :: start_position

    real, dimension(1:NUNITS), intent(Out) :: global_ACC_array

#if NTH > 1
    ! Arrays prefixed with 'local_' should be declared using the '__local' modifier in C kernel version
    real, dimension(1:NTH) :: local_ACC_array  !$ACC MemSpace local
#endif
    real :: local_ACC

    call get_group_id(group_id,0)
#if NTH > 1
    call get_local_id(local_id,0)
#endif
    nthreads = NUNITS*NTH
    ndrange = (500 * 500)
    ndrange_padded = ndrange    
    if (mod(ndrange_padded, (NUNITS*NTH) ) > 0) then
        ndrange_padded = ( (ndrange_padded/ (NUNITS*NTH) ) +1)* (NUNITS*NTH)
    end if
    chunk_size = ndrange_padded / NUNITS
#if NTH > 1
    local_chunk_size = chunk_size / NTH
#else
    local_chunk_size = chunk_size
#endif
    start_position = chunk_size * group_id
    local_ACC = 0

    do idx=0, (local_chunk_size - 1)
        r_iter = (start_position + (local_id + (NTH * idx)))
        if ((r_iter < ndrange)) then
            ! 
            j_range = ((500 - 1) + 1)
            k_range = ((500 - 1) + 1)
            j_rel = (r_iter / k_range)
            j = (j_rel + 1)
            k_rel = (r_iter - (j_rel * k_range))
            k = (k_rel + 1)

            call reduce_scal(ARRAY(j,k),local_ACC)
        end if
    end do

#if NTH > 1
    local_ACC_array(local_id) = local_ACC

#ifdef BARRIER_OK
    call barrier(CLK_LOCAL_MEM_FENCE)
#endif

    local_ACC = 0
    do r_iter=1, NTH
        local_ACC = (local_ACC + local_ACC_array(r_iter))
    end do
#endif
    global_ACC_array(group_id) = local_ACC

end subroutine 

### Combined stencils and boundary conditions

p1(i) = f(p0(i-1),p0(i+1))
p1(i-1) = f(p0(i-2),p0(i))
p1(i+1) = f(p0(i),p0(i+2))

p2(i) = f(p1(i-1),p1(i+1))
= f(
    f(p0(i-2),p0(i)),
    f(p0(i),p0(i+2))
    )
    
So at this point we have already p0(i-2)

But if we consider the edge case, p2(1):

p1(1) = f(p0(0),p0(1))
p1(0) = p0(0)
p1(2) = f(p0(1),p0(3))

p2(1) = f(p1(0),p1(2))
= f(
    p0(0),
    f(p0(1),p0(3))
    )
So because of the boundary condition, there is no issue, because p0(i-2) is never accessed.

## 2021-06-02

TODO!

A small problem is that currently, the call args for subs called in the superkernel must have the same name as the sig args of the subs. 

Regarding the VT, I think for now I will simply treat all VT as Input arguments. If that breaks, I can do the right thing.

The main program that is currently generated had better be a superkernel with a case statement etc.
As for OpenCL C translation the INTENT does not matter anyway, we can leave it as InOut
What I don't know is if the scalars need to be arrays of 1 elt and turned into pointers

The other issue is that I must translate the scalarised functions as well. 

See also "OpenCLC: Passing array slices and returning scalars into array elements" below  



## 2021-06-01

Started on ShallowWater2D. Turns out that the argument order in scalarisedArgsList and in the actual arg list of scalarised functions was not the same, fixed this.

Now debugging a simple fold + stencil map. Problem is that the accumulator is marked as VT in the map and it must be VI to work.
But it should actually be VT. But when I do that, the arg gets removed as a temp. This would be OK inside a stage but not across stage.
I am surprised this is broken.

Note that the output of the fold is marked as VO and that is also wrong (it is not an Out for Main), that should be fixed in MemoryReduction.pm

To solve the issue with VT in the stages, we need the following analysis:

- if we encounter a VT on the RHS before we encounter one on the LHS, then that VT becomes VI. I don't think it is possible to encounter a VT on the LHS after encountering one on the RHS.
- if we encounter a VT on the LHS but never on the RHS, then that VT becomes VO
- if we encounter a VT on the LHS an later on the RHS, then that VT stays VT

This is somewhere in generateStageKernel'

This is the wrong approach. Essentially, every stage but the last one is a Fold, so the acc must be VO; the last stage is a Map, and the only reason to have the previous stages is if it uses one or more of those accs. 

So I must make a list of all accumulators in the preceding stages, make all of them VO. This is easy, it is simply the LHS

So we do 
fold_ast_stages = init ast_stages
fold_ast_stages' = map make_acc_VT_VO fold_ast_stages
map_ast_stage = last ast_stages
ast_stages' =  fold_ast_stages' ++ [map_ast_stage']

 and make all these VI in the Map and any Fold that uses them

## 2021-05-31

I fixed the range for the global index iterator, to avoid out-of-bounds accesses. I also verified that 3-D Fortran code is properly converted to 1-D.
TEST 16 fails. All other tests compile but there are many warnings on -Wunused-dummy-argument

Currently stuck on some bug in the scalariser: it removes a non-map argument, see Analysis/ArgumentIODirs.pm line 767.
Part of the reason is that somehow it expects the same variable name for the call arg and the sig arg.
When they have the same name, it is still not right because the argument is not treated as non-map.

I solved this very simply: this is actually a fix for AutoParallelFortran so I switched it off.

## 2021-05-21

A simple stencil-map does not generate correct Fortran for the shell subroutine: we get

subroutine f(acc_0, v_s_0, v_1)
    real, intent(In) :: acc_0
    real, dimension(1:500), intent(In) :: v_s_0
    real, dimension(1:500), intent(Out) :: v_1

    ! Temp vars

    ! Call to the original scalarised subroutine

    call f_scal(acc_0, v_s_0(1), v_s_0(2), v_s_0(3))

end subroutine f

but we should get

subroutine f(acc_0, v_s_0, v_1)
    real, intent(In) :: acc_0
    real, dimension(2), intent(In) :: v_s_0
    real, intent(Out) :: v_1

    ! Temp vars

    ! Call to the original scalarised subroutine

    call f_scal(acc_0, v_s_0(1), v_s_0(2), v_1)

end subroutine f




## 2021-05-20

SOLVED!
<!--
There is a problem with the trivial fold:

- In the shell subroutine f(acc_0, v_0, acc_1) we get

    call f_scal(acc, v_0)
    acc_0 = acc

and it should be 

    acc = acc_0
    call f_scal(acc, v_0)
    acc_1 = acc

The reason for this is the following:

MemoryReduction-exe: (
      origNamesList: ("f",[ ("acc", [("acc_1",Out)] ), ("v",[("v_0",In)]), ("acc",[("acc_0",Out)]) ] ),
      origNames: {"f" => {
            "acc" => [("acc_0",Out)],
            "v" =>[("v_0",In)]
            }
            },
      "f",
      "acc")

      So there is a problem here that acc_1 should be In or InOut, not Out! FIXME in the Perl code MemoryReduction around line 1257
      Furthermore, this should lead to 
      "acc" => [("acc_0",Out),("acc_1",In)]
      or even
      "acc" => {"acc_0" =>Out,"acc_1" =>In} , FIXME in CodeGeneration.hs, the creation of origNames from origNamesList
-->

## 2021-05-19

Been working on getting actual OpenCL Fortran to generate to ASTInstance.hs
Current status is that a simple fold-map example without stencils seems to work full chain.
Next step is to test a stencil, then two stencils

I think the detection of non-stream arguments still needs to be improved: we should use Accesses etc to see if an array is not using all iterators. If so, it is not a stream.

## 2021-05-17

Trivial tests for map and fold (13, 14, 15) also HANG on Substitute vectors (recursive), which is really silly.


## 2021-05-14

Trying to get TEST 10 to work with `noStencilRewrites = True` has led to additional arguments and declarations to get rid of.

What we need to do is look at the stage AST: all Vec vars that occur both on LHS and RHS can become local scalars. From the remaining ones, those in LHS are Out, those in RHS are In, regardless of their VO/VI because these are for global main. I think a simple way to do this is:
- split the tuples, [(,)] -> ([],[]) so unzip
- get all vecs from LHS and RHS, we do this somewhere already
- do the Data.List.intersect , these are local scalars
- the difference Data.List.(\\) with LHS are Out


Fortran code generation should only be correct for the final stage `DecomposeExpressions` but for both `noStencilRewrites = True` and `noStencilRewrites = False`

* TEST 8 HANGS for noStencilRewrites = True on "Substitute vectors (recursive)" but passes with noStencilRewrites = False

etan_0 :: Vec 500 Float
wet_0 :: Vec 500 Int
un_0 :: Vec 500 Float

h_0 :: Vec 500 Float
u_0 :: Vec 500 Float
wet_1 :: Vec 500 Int

update_map_24 :: (Float,Float) -> (Float,Float,Int)
shapiro_map_16 :: (Int,SVec 3 Float) -> Float

main :: (Vec 500 Float,Vec 500 Int,Vec 500 Float) -> (Vec 500 Float,Vec 500 Float,Vec 500 Int)
main (etan_0,wet_0,un_0) =
  let
    s1 = [-1,0,1]
    etan_s_0 = stencil s1 etan_0
    eta_0 =  map shapiro_map_16 (zipt (wet_0,etan_s_0))
    (h_0,u_0,wet_1) = unzipt $ map update_map_24 (zipt (eta_0,un_0))
  in
    (h_0,u_0,wet_1)

-- Go trough all lines of the ast and do a recursive substitution on the lines with an output vector in the LHS
substituteVectors :: TyTraCLAST -> TyTraCLAST
substituteVectors ast' 
    | noStencilRewrites = map (substitute_vec_rec ast') (filter lhs_is_VO_or_VT_vec ast') 
    | otherwise =  map (substitute_vec_rec ast') (filter lhs_is_output_vec ast')

(Vec VT (Scalar VDC DFloat "eta_0"),
Map (Function "shapiro_map_16" []) 
    (ZipT [
      Vec VI (Scalar VDC DInt "wet_0"),
      Vec VS (SVec 3 (Scalar VDC DFloat "etan_s_0"))
      ]
    )
)
(Vec VO (Scalar VDC DFloat "h_0"),Elt 0 (UnzipT (Map (Function "update_map_24" []) (ZipT [Vec VT (Scalar VDC DFloat "eta_0"),Vec VI (Scalar VDC DFloat "un_0")]))))
(Vec VO (Scalar VDC DFloat "u_0"),Elt 1 (UnzipT (Map (Function "update_map_24" []) (ZipT [Vec VT (Scalar VDC DFloat "eta_0"),Vec VI (Scalar VDC DFloat "un_0")]))))
(Vec VO (Scalar VDC DInt "wet_1"),Elt 2 (UnzipT (Map (Function "update_map_24" []) (ZipT [Vec VT (Scalar VDC DFloat "eta_0"),Vec VI (Scalar VDC DFloat "un_0")]))))

So the reason is the ZipT  that has a Vec VS; without the ZipT (TEST 10) it does not hang but crashes on 

MemoryReduction-exe: (Vec VT (Scalar VT DDC "vec_h_0_1"),Elt 0 (Vec VT (Scalar VT DDC "vec_h_0_0")))
in CodeGeneration.hs:224

## 2019-11-13

I have started processing the LES. I added a number of macros to make the source suitable for conversion:

The existing macros used are

            #define WV_OPENCL
            #define WV_NEW
            #define NO_GLOBAL_SOR 
            #define TWINNED_BUFFER 
            #define NO_IO 
            #undef NO_FILE_IO 
            #define IFBF 1 
            #define IADAM 0 
            #undef I_IFDATA_OUT
            #undef I_AVEFLOW
            #define I_ANIME

The new ones are

            #define NO_BOUNDS_CALCS 
            #define INLINE_VEL2
            #define LES_EXTERNAL_DELX1
            #define SEPARATE_P_ARRAYS

- Boundary calculations are assumed to be done on the host.
- As I want to reduce arrays, I want to use the original `vel2` but we don't have an inliner yet so I did that manually.
- In `les.f95`, a 1-D array `delx1` is computed, I assume this will be done once on the host.
- Instead of a 4-D `p` array I have two 3-D arrays `p0` and `p1`.

The current main issue is that non-map/fold args that are arrays are not passed as arrays but are also scalarised. To avoid this, I must identify the arrays as non-map/fold. 
We could assume that the programmer does this, or we can use the dimension analysis. Identifying these arguments earlier is better anyway, but there does not seem to be a single working criterion.
A good heuristic might be:
- how many dimensions is the problem? `$ndims`
- what is the max size in any dimension? `@max_szs`
- any array of lower dimensionality is automatically not a stream
- any array of the correct dimensionality but much smaller than the `@max_szs` is not a stream
- "much smaller" is based on the assumption that we have a domain and then `$k` points for a halo. Any array where any dimension is smaller than $max_sz - $k should not be a stream

So let's assume we have this in the `rf4a.cfg`:

      NDIMS = 3
      MAX_SZS = 100, 100, 100 
      HALO_EXTENT = 3

The change to the code is in `_classify_accesses_and_emit_AST` (line 708) in `RefactorF4Acc::Analysis::ArrayAccessPatterns`; but I think we need the same analysis in `RefactorF4Acc::Refactoring::Streams` because of `rename_array_accesses_to_scalars` which is needed for the MemoryReduction pass.

BETTER: use 'LoopIters'

!!! unzipt $ fold should just be fold !!!


## Generate Fortran from the original TyTraCL

Although this might seem obvious, it breaks due to several reasons. 

            call f1(v_0(idx), v_1)

- `v_1` is not recognised as an array because it is not an I/O argument
- It is not declared either            
- So what we should do: if the LHS of a Map is an original Vec, but not VI or VO, we should declare it using vSz

Turns out this is totally wrong, because if we don't eliminate the stencils then every map must be a stage.
So the right way is to have a separate set of rewrite rules that do not touch the stencil. 

It may be enough to not substitute any VT vecs. But that would mean that we can't remove a map in map f map g. 
So probably we should allow substitution of VT but _not_ in Stencil.



## OpenCL Code

The host-side code will have to be manual for now.

## Testing and Examples

### Map-only

I think I should test this with an example where I calculate a derivative of the normalised value of a property.

So v-mean(v) stenciled at -1 and +1; for the edge points we have a condition check. First I do this 1-D, then 2-D, then I do it again in actual Fortran

What I expect here is that the intermediate array v_norm will disappear

            subroutine calc_mean(acc_in,v_in,acc_out)
                  acc_out = acc_in+v_in/v_sz
            end subroutine calc_mean

            subroutine calc_norm(mean_v,v_in,v_out)
                  v_out = v_in-mean_v
            end subroutine calc_norm

            subroutine calc_deriv(v_in_1,v_in_2, v_out)
                  v_out = (v_in_2 - v_in_1)/2
            end subroutine calc_deriv

In TyTraCL we have

            v_mean = fold calc_mean 0 v
            v_norm = map (calc_norm v_mean) v
            s = [-1,1]
            v_norm_s = stencil s v_norm
            v_norm_deriv = map calc_deriv v_norm_s

In Fortran this becomes            

            subroutine calc_norm_deriv(v, v_norm_deriv)
                  implicit none
                  real, dimension(VSZ), intent(in) :: v
                  real, dimension(VSZ), intent(out) :: v_norm_deriv
                  real, dimension(VSZ) :: v_norm
                  real :: mean_v
                  integer :: idx
                  mean_v=0
                  do idx=1,VSZ                  
                        mean_v = mean_v+v_in(idx)/VSZ
                  end so

                  do idx=1,VSZ                        
                        v_norm(idx) = v_in(idx)-mean_v
                  end do

                  do idx=1,VSZ                        
                        v_norm(idx) = v_in(idx)-mean_v
                  end do

                  do idx=1,VSZ
                        if (idx==1) then
                              v_norm_deriv(idx) = (v_norm(idx) -v_normn(idx+1)/2
                        elsif (idx==VSZ) then
                              v_norm_deriv(idx) = (v_norm(idx-1) -v_normn(idx)/2
                        else
                              v_norm_deriv(idx) = (v_norm(idx-1) -v_normn(idx+1)/2
                        end if
                  end do

            end subroutine calc_norm_deriv

The final program is something simple like

program main
      implicit none
      real, dimension(VSZ) :: v
      real, dimension(VSZ) :: v_norm_deriv            
      integer :: idx

      ! populate v
      do idx=1,VSZ
            v(i) = 1+2*idx+idx*idx
      end do

      ! run the calculation
      do idx=1,VSZ
            call stage_kernel_1(...)
      end do
end program main




## Avoiding double-buffering

### The problem and some analysis

The current approach creates an in and out array for every inout array. The typical problem is that a stencil would use the updated value rather than the old value. But the actual problem is that even if the program used double buffering, then both buffers are turned into two buffers. So I think I should go through the code and identify the following pattern:

            un = f(u)
            u = g(un)

In this case, both u an un are inout but we only need one of them, and it does not really matter which one. So we pick the first read on, i.e. u, and we replace un with u in SSA fashion

How do we find this out? we do per function a deps list for all output vars. This should tell us that un depends on u in f, and u depends on un in g. Then we do a global analysis

      subroutine f(u,un)
            un = f'(u)
      end
      subroutine g(un,u)
            u = g'(un)
      end

      subroutine kernel(u1,un1)
            call f(u1, un1)
            call g(un1, u1)
      end            

un1 is out for f and in for g, so to un1's deps in g I add un1's deps from f, i.e. u.
u in g depends on un which depends on u in f, so that we have u1 depending on u1. In short, I think the solution is to say that un must be a local array. I think that should automatically lead to its being eliminated.

### The key insight: local arrays

Intermediate arrays should not be in, out or inout, but _local_.  I verified this and indeed, any array that I make a local disappears. So what I should do is this:

- Combine all subroutines in a time loop (assuming no I/O) into a single subroutine which has no subroutine calls => write that inliner!
- For that subroutine, do the aggressive new IODir analysis
- Then check if the Out and InOut arguments are needed: if they are not used in any code downstream from the kernel subroutine, they are not needed so Out should become local and InOut should become In.

## OpenCLC: Passing array slices and returning scalars into array elements

- We use array slices and also return scalar values into array elements, see

      {test_return_to_array_elt,test_pass_array_slice},{f90,c}

for the conversions.

We need to add this to

      RefactorF4Acc::Translation::OpenCLC

The current (2019-11-06) status is that the slices are now done, I need to verify if return into array elt works.

## More general case for stencils

The stencil currently is defined for non-constant accesses only, I could generalise this using the algorithm in

See `MemoryReduction/2018-10-30-stencil-algo.txt`, a copy of `~wim/FortranRefactoring/2018-10-30-stencil-algo.txt` 

## How to deal with iteration?

      (read_only_vs, iter_vs) = map f v_ins
      iter_vs' = iterate test calc_iter read_only_vs iter_vs
      v_out = map f (read_only_vs, iter_vs')

It seems clear that the `iterate` call must become one or more stages; there is no reason to do this on the device, so we can probably keep the original code.

Essentially, for the SOR we have

      p_s = stencil s1 p
      p = map sor (zipt (p_s,rhs))

and it's a single map so no particular actions

## LES in TyTraCL?

In `/Users/wim/SoC_Research/TyTra/tytra/Type-Transformations-FPGA/TyTraHLL` we have

`/Users/wim/SoC_Research/TyTra/tytra/Type-Transformations-FPGA/TyTraHLL/TytraHLL-LES.hs`

These are Haskell sketches. What I need is a proper TyTraCL version based on the GPU version.
If I would ignore the boundaries, it might be possible ...

I think the best thing to do is to use velfg/vel2 as example.

## Complexity Analysis: Combinatorial explosion

Given a stencil of m points, called k times, we'll have m**k operations.
I don't think we can avoid the actual computations, but we can avoid reading m**k values from main memory:
- The actual number of unique values accessed is much smaller. For example a 4-point stencil +/-1 will after k iterations result in 2*k*k unique values (instead of 4**k). A 2-point stencil would be 2*k (instead of 2**k) values. for a 6-point stencil, we get 8 cube sections, so two cubes, i.e. 2*k*k*k (as opposed to 6**k)
We can create a small memory that has the iterator values and the actual array value at the point, and as this is small, we can search it linearly for the value needed. A kind of very specialised cache.
In this way, the memory BW will not grow. The computation requirement still grows very fast though.

Compared to the original: say that we have k iterations, we have k intermediate arrays, so on the whole order of k*m operations, compared with m**k, 
m**k/k/m

say m=6 and k=5
6**5/5/6 = 6**4/5 = 260x

See CombinatorialExplosion.ods

Looking at e.g. the GeForce GTX TITAN:

threads: 2688
clock 837 MHz
Memory Bandwidth (GB/sec) 288

So per ns, we can read 77 words from the memory, to be divided amongst 2688 threads. So per thread it takes 35 ns for a word (2688/77), i.e. about 30 cycles can be spend on computation before it becomes compute dominated. 

